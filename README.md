# ğŸ¤– Agente de Trading: Ensemble RL + LLM

Sistema avanÃ§ado de trading automatizado combinando **3 algoritmos de Reinforcement Learning** com **anÃ¡lise de sentimento via LLM** para operar futuros de criptomoedas na Binance.

## âœ¨ Novidades v2.0

### ğŸ†• **Ensemble de Modelos RL**
- **PPO** (Proximal Policy Optimization) - Conservador e estÃ¡vel
- **SAC** (Soft Actor-Critic) - Agressivo, ideal para trading contÃ­nuo
- **TD3** (Twin Delayed DDPG) - AÃ§Ãµes contÃ­nuas com menor ruÃ­do
- **VotaÃ§Ã£o inteligente** combinando previsÃµes dos 3 modelos

### ğŸ§  **AnÃ¡lise de Sentimento com LLM**
- Coleta automÃ¡tica de notÃ­cias (NewsAPI + RSS feeds)
- AnÃ¡lise de sentimento via **GPT-4/GPT-3.5**, **Claude** ou **FinBERT** (local)
- Features temporais (1h, 6h, 24h) com decay
- Detecta tendÃªncias e volatilidade de sentimento

### ğŸ“Š **Sistema Completo**
- **9+ features de sentimento** integradas ao agente
- **32+ features totais** (mercado + sentimento + portfolio)
- **GestÃ£o de risco** avanÃ§ada com Kelly Criterion
- **Paper e Live trading** com monitoramento 24/7

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ **InstalaÃ§Ã£o**

```powershell
# Clone e navegue
git clone <seu-repositorio>
cd AGENTE_TRANDING

# Ambiente virtual
python -m venv venv
.\venv\Scripts\Activate.ps1

# Instale dependÃªncias
pip install -r requirements.txt
```

### 2ï¸âƒ£ **ConfiguraÃ§Ã£o**

```powershell
# Copie template de variÃ¡veis
cp .env.example .env

# Edite .env com suas API keys:
# - BINANCE_API_KEY (obrigatÃ³rio)
# - OPENAI_API_KEY (recomendado para LLM)
# - NEWSAPI_KEY (opcional, 500 requests/dia grÃ¡tis)
```

### 3ï¸âƒ£ **Teste o Sistema**

```powershell
# Verifica se tudo estÃ¡ OK
python test_system.py

# Deve mostrar:
# âœ… Imports OK
# âœ… config.yaml OK
# âœ… Environment OK
# âœ… NotÃ­cias coletadas
```

### 4ï¸âƒ£ **Treinamento**

```powershell
# Coleta dados histÃ³ricos
python -m src.data.data_collector

# Treina ensemble (PPO + SAC + TD3)
python -m src.training.ensemble_trainer

# Aguarde ~30-60min
# Modelos salvos em: models/ensemble/
```

### 5ï¸âƒ£ **Trading**

```powershell
# Paper trading (SEM RISCO)
python -m src.execution.ensemble_executor

# Output:
# ğŸ“° Sentimento: 0.654 (23 notÃ­cias)
# ğŸ¤– Votos: {'ppo': 1, 'sac': 1, 'td3': 0}
#    AÃ§Ã£o Final: 1 (Long)
#    ConcordÃ¢ncia: 66.7%
# ğŸ’µ PreÃ§o: $94,523.45
# âœ… AÃ§Ã£o executada
```

**âš ï¸ IMPORTANTE:** Use primeiro a testnet da Binance para testes!

---

## ğŸ“š DocumentaÃ§Ã£o Completa

- **[GUIA_ENSEMBLE_LLM.md](GUIA_ENSEMBLE_LLM.md)** - Guia completo de uso (RECOMENDADO)
- **[ARQUITETURA_TECNICA.md](ARQUITETURA_TECNICA.md)** - Detalhes tÃ©cnicos da arquitetura
- **[COMPARACAO_FREQTRADE.md](COMPARACAO_FREQTRADE.md)** - ComparaÃ§Ã£o com Freqtrade
- **[INTEGRACAO_FREQTRADE.md](INTEGRACAO_FREQTRADE.md)** - Como integrar com Freqtrade

---

## ğŸ¯ Features Principais

### **1. Ensemble de RL** ğŸ¤–ğŸ¤–ğŸ¤–
```python
# 3 modelos votam em cada decisÃ£o
PPO: Long (confianÃ§a: 70%)
SAC: Long (confianÃ§a: 90%)  
TD3: Flat (confianÃ§a: 60%)
â†’ Resultado: Long (consenso ponderado)
```

**EstratÃ©gias de votaÃ§Ã£o:**
- `majority` - VotaÃ§Ã£o simples
- `weighted` - Ponderado por performance (padrÃ£o)
- `confidence` - Ponderado por certeza
- `best` - Usa apenas melhor modelo
- `average` - MÃ©dia das previsÃµes

### **2. AnÃ¡lise de Sentimento** ğŸ§ 
```python
# Pipeline completo
NotÃ­cias â†’ LLM (GPT/Claude/FinBERT) â†’ Features
â†“
sentiment_1h: 0.8 (bullish)
sentiment_6h: 0.6 (bullish)
sentiment_24h: 0.3 (neutral)
trend: +0.5 (melhorando)
volatility: 0.2 (baixa)
```

**Fontes:**
- NewsAPI (500 requests/dia grÃ¡tis)
- RSS Feeds (CoinTelegraph, CoinDesk, etc)
- AtualizaÃ§Ãµes a cada 1h

**Modelos LLM:**
- OpenAI GPT-3.5/GPT-4 (pago, melhor qualidade)
- Anthropic Claude (alternativa)
- FinBERT local (grÃ¡tis, offline)

### **3. GestÃ£o de Risco** ğŸ›¡ï¸
```python
âœ… Kelly Criterion para position sizing
âœ… Stop Loss automÃ¡tico (2%)
âœ… Take Profit automÃ¡tico (4%)
âœ… Max Drawdown protection (15%)
âœ… ValidaÃ§Ã£o antes de cada trade
```

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Coleta de Dados                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Binance API â†’ OHLCV + Indicadores           â”‚
â”‚ NewsAPI/RSS â†’ NotÃ­cias â†’ LLM â†’ Sentimento  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Trading Environment                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Observation: [Market + Sentiment + Portfolio]â”‚
â”‚ Actions: [Flat, Long, Short]                â”‚
â”‚ Reward: PnL - Costs - Penalties            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Ensemble RL                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PPO Model â†’ Vote 1                          â”‚
â”‚ SAC Model â†’ Vote 2  â†’ Combiner â†’ Action    â”‚
â”‚ TD3 Model â†’ Vote 3                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Risk Management                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Validate Stop Loss / Take Profit            â”‚
â”‚ Check Max Drawdown                          â”‚
â”‚ Calculate Position Size (Kelly)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Execution                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Paper Trading / Live Trading (Binance)     â”‚
â”‚ Logging & Metrics                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Estrutura do Projeto

```
AGENTE_TRANDING/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data_collector.py         # Coleta OHLCV + indicadores
â”‚   â”œâ”€â”€ environment/
â”‚   â”‚   â””â”€â”€ trading_env.py            # Gymnasium environment
â”‚   â”œâ”€â”€ sentiment/                     # ğŸ†• AnÃ¡lise de sentimento
â”‚   â”‚   â”œâ”€â”€ news_collector.py         # Coleta notÃ­cias
â”‚   â”‚   â”œâ”€â”€ llm_analyzer.py           # GPT/Claude/FinBERT
â”‚   â”‚   â””â”€â”€ sentiment_processor.py    # Features numÃ©ricas
â”‚   â”œâ”€â”€ models/                        # ğŸ†• Ensemble
â”‚   â”‚   â””â”€â”€ ensemble_model.py         # VotaÃ§Ã£o de modelos
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train.py                  # Treina modelo Ãºnico
â”‚   â”‚   â””â”€â”€ ensemble_trainer.py       # ğŸ†• Treina PPO+SAC+TD3
â”‚   â”œâ”€â”€ risk/
â”‚   â”‚   â””â”€â”€ risk_manager.py           # Kelly, SL, TP
â”‚   â””â”€â”€ execution/
â”‚       â”œâ”€â”€ executor.py               # Executor simples
â”‚       â””â”€â”€ ensemble_executor.py      # ğŸ†• Executor completo
â”œâ”€â”€ data/                              # Dados histÃ³ricos
â”œâ”€â”€ models/                            # Modelos treinados
â”‚   â””â”€â”€ ensemble/                     # ğŸ†• PPO, SAC, TD3
â”œâ”€â”€ logs/                              # Logs e mÃ©tricas
â”œâ”€â”€ config.yaml                        # ConfiguraÃ§Ã£o principal
â”œâ”€â”€ .env.example                       # Template de credenciais
â”œâ”€â”€ requirements.txt                   # DependÃªncias
â”œâ”€â”€ test_system.py                     # ğŸ†• Teste completo
â”œâ”€â”€ README.md                          # Este arquivo
â”œâ”€â”€ GUIA_ENSEMBLE_LLM.md              # ğŸ†• Guia de uso
â”œâ”€â”€ ARQUITETURA_TECNICA.md            # ğŸ†• Docs tÃ©cnicas
â””â”€â”€ COMPARACAO_FREQTRADE.md           # ComparaÃ§Ã£o

ğŸ†• = Novos arquivos v2.0
```

---

## ğŸš€ Uso

### Fase 1: Coletar Dados

```bash
python -m src.data.data_collector
```

Isso irÃ¡:
- Baixar dados OHLCV da Binance
- Calcular indicadores tÃ©cnicos
- Normalizar os dados
- Dividir em treino/validaÃ§Ã£o/teste

### Fase 2: Treinar o Agente

```bash
python -m src.training.train --mode train
```

O treinamento irÃ¡:
- Criar um ambiente de simulaÃ§Ã£o
- Treinar o agente PPO por 100.000 timesteps (configurÃ¡vel)
- Salvar o melhor modelo em `models/`
- Gerar logs em `logs/`

Para visualizar o treinamento no TensorBoard:

```bash
tensorboard --logdir logs/tensorboard
```

### Fase 3: Avaliar o Modelo

```bash
python -m src.training.train --mode eval --model models/ppo_trading_agent_XXXXXXXX.zip
```

### Fase 4: Executar em Paper Trading

```bash
python -m src.execution.executor --model models/ppo_trading_agent_XXXXXXXX.zip --mode paper
```

### Fase 5: Executar em Live Trading (âš ï¸ USE COM CAUTELA)

```bash
python -m src.execution.executor --model models/ppo_trading_agent_XXXXXXXX.zip --mode live
```

## ğŸ“ Estrutura do Projeto

```
AGENTE_TRANDING/
â”œâ”€â”€ config.yaml              # ConfiguraÃ§Ãµes principais
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ .env.example            # Template de variÃ¡veis de ambiente
â”œâ”€â”€ README.md               # Este arquivo
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ environment/        # Ambiente Gymnasium
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ trading_env.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/              # Coleta e processamento de dados
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_collector.py
â”‚   â”‚
â”‚   â”œâ”€â”€ risk/              # GestÃ£o de risco
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ risk_manager.py
â”‚   â”‚
â”‚   â”œâ”€â”€ training/          # Treinamento do agente
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”‚
â”‚   â””â”€â”€ execution/         # ExecuÃ§Ã£o ao vivo
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ executor.py
â”‚
â”œâ”€â”€ data/                  # Dados processados (gerado)
â”œâ”€â”€ models/                # Modelos treinados (gerado)
â””â”€â”€ logs/                  # Logs de treinamento e trading (gerado)
```

## âš™ï¸ ConfiguraÃ§Ã£o

Edite `config.yaml` para ajustar:

- **SÃ­mbolo e timeframe** do mercado
- **Indicadores tÃ©cnicos** a usar
- **HiperparÃ¢metros do RL** (learning rate, batch size, etc.)
- **ParÃ¢metros de risco** (stop loss, take profit, alavancagem)
- **Tamanho de posiÃ§Ã£o** e capital inicial

## ğŸ§  Como Funciona

### 1. Ambiente de RL (TradingEnv)

O ambiente simula um mercado de trading onde o agente:
- **Observa:** PreÃ§os, indicadores tÃ©cnicos e estado da carteira
- **Age:** Fica Flat, abre Long ou abre Short
- **Recebe recompensa:** Baseado no PnL e custos de transaÃ§Ã£o

### 2. FunÃ§Ã£o de Recompensa

$$R_t = (\text{Balance}_t - \text{Balance}_{t-1}) - (\text{Trade Cost} \times \text{Action Changed})$$

A recompensa incentiva o agente a:
- Maximizar lucros
- Minimizar custos de transaÃ§Ã£o
- Evitar overtrading

### 3. GestÃ£o de Risco

O Risk Manager aplica regras hardcoded:
- **Kelly Criterion** para tamanho de posiÃ§Ã£o
- **Stop Loss automÃ¡tico** (2%)
- **Take Profit automÃ¡tico** (4%)
- **Controle de Drawdown** (15% mÃ¡ximo)
- **Limite de alavancagem** (3x)

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

O sistema rastreia:
- Win Rate (taxa de vitÃ³ria)
- Total de trades
- PnL (Profit and Loss)
- Drawdown
- Sharpe Ratio (planejado)

## âš ï¸ Avisos Importantes

1. **NÃƒO USE EM PRODUÃ‡ÃƒO SEM TESTES EXTENSIVOS**
2. Comece sempre com a **testnet da Binance**
3. Use **Paper Trading** antes de arriscar capital real
4. O passado **nÃ£o garante** retornos futuros
5. Trading automatizado envolve **riscos significativos**
6. Nunca invista mais do que pode perder

## ğŸ”§ Troubleshooting

### Erro: "Module not found"
```bash
# Certifique-se de estar no diretÃ³rio raiz
cd AGENTE_TRANDING
python -m src.data.data_collector
```

### Erro: "API Key invÃ¡lida"
- Verifique se o `.env` estÃ¡ configurado corretamente
- Certifique-se de usar chaves da testnet primeiro

### Modelo nÃ£o converge
- Aumente `total_timesteps` no `config.yaml`
- Ajuste `learning_rate` (tente 0.0001 ou 0.0005)
- Verifique se os dados estÃ£o normalizados

## ğŸ“š ReferÃªncias

- [Stable Baselines3 Docs](https://stable-baselines3.readthedocs.io/)
- [Gymnasium Documentation](https://gymnasium.farama.org/)
- [Binance Futures API](https://binance-docs.github.io/apidocs/futures/en/)
- [Kelly Criterion](https://en.wikipedia.org/wiki/Kelly_criterion)

## ğŸ“ LicenÃ§a

Este projeto Ã© fornecido "como estÃ¡" para fins educacionais.

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Abra uma issue ou pull request.

---

**âš ï¸ DISCLAIMER:** Este software Ã© fornecido para fins educacionais. O uso em produÃ§Ã£o Ã© por sua conta e risco. Os desenvolvedores nÃ£o se responsabilizam por perdas financeiras.
